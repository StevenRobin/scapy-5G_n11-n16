# Windowsä¼˜åŒ–çš„Scapyå¯¼å…¥æ–¹å¼
import os
import sys

# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥é¿å…Scapyåœ¨Windowsä¸Šçš„å¯¼å…¥é—®é¢˜
os.environ['SCAPY_USE_PCAPDNET'] = '0'
os.environ['SCAPY_USE_WINPCAPY'] = '0'

# åˆ†åˆ«å¯¼å…¥éœ€è¦çš„Scapyæ¨¡å—ï¼Œé¿å…ä½¿ç”¨ scapy.all
from scapy.utils import rdpcap, wrpcap
from scapy.packet import Raw, Packet
from scapy.layers.inet import IP, TCP
from scapy.layers.l2 import Ether
from scapy.fields import BitField, ByteField

print("Scapyæ¨¡å—å¯¼å…¥æˆåŠŸ")

from hpack import Encoder, Decoder
import json
import re
import copy
from tqdm import tqdm
from typing import Dict, Any, List, Optional
import os
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from functools import partial
import tempfile
import gc
import time

# å…¨å±€é…ç½®å‚æ•° - åˆå§‹å€¼
INITIAL_SIP1 = "40.0.0.1"
INITIAL_DIP1 = "50.0.0.1"
INITIAL_IMSI1 = "460012300000001"
INITIAL_IMEI14 = "86111010000001"
INITIAL_GPSI1 = "8613900000001"
INITIAL_PDUADDR1 = "100.0.0.1"
INITIAL_DNN1 = "dnn600000001"
INITIAL_TAC1 = "100001"
INITIAL_CGI1 = "010000001"
INITIAL_UPFIP1 = "80.0.0.1"
INITIAL_UPTEID1 = 0x70000001
INITIAL_GNBIP1 = "70.0.0.1"
INITIAL_DNTEID1 = 0x30000001
INITIAL_SPORT1 = 5001
INITIAL_SPORT2 = 5002  # sport1 + 1
INITIAL_SPORT3 = 5003  # sport1 + 2

# å…¨å±€å˜é‡ - åŠ¨æ€æ›´æ–°
sip1 = INITIAL_SIP1
dip1 = INITIAL_DIP1
auth1 = dip1
auth2 = sip1
imsi1 = INITIAL_IMSI1
imei14 = INITIAL_IMEI14
gpsi1 = INITIAL_GPSI1
PduAddr1 = INITIAL_PDUADDR1
dnn1 = INITIAL_DNN1
tac1 = INITIAL_TAC1
cgi1 = INITIAL_CGI1
upfIP1 = INITIAL_UPFIP1
upTEID1 = INITIAL_UPTEID1
gnbIP1 = INITIAL_GNBIP1
dnTEID1 = INITIAL_DNTEID1
sport1 = INITIAL_SPORT1
sport2 = INITIAL_SPORT2
sport3 = INITIAL_SPORT3

# IPå’Œç«¯å£æ•°é‡é…ç½®
IP_NUM = 2000      # ç»Ÿä¸€çš„IPå¾ªç¯æ•°é‡
SPORT_NUM = 20000  # sportç«¯å£æ•°é‡
TAC_NUM = 10000000 # TACå¾ªç¯æ•°é‡

def get_port_mapping():
    """åŠ¨æ€è·å–å½“å‰ç«¯å£æ˜ å°„ï¼Œé¿å…å…¨å±€å˜é‡å†²çª"""
    return {
        20000: sport1,   # 20000 -> 10001
        51239: sport2,   # 51239 -> 10003
        55983: sport3    # 55983 -> 10004
    }

# æ–°å¢å˜é‡é€’å¢å‡½æ•°
def update_batch_variables(iteration):
    """æ›´æ–°ä¸€ä¸ªæ‰¹æ¬¡çš„æ‰€æœ‰å˜é‡"""
    global sip1, dip1, auth1, auth2, imsi1, imei14, gpsi1, PduAddr1, dnn1, tac1, cgi1
    global upfIP1, upTEID1, gnbIP1, dnTEID1, sport1, sport2, sport3
    
    # IPåœ°å€å¾ªç¯é€’å¢ - ä½¿ç”¨ç»Ÿä¸€çš„IP_NUM
    ip_iteration = iteration % IP_NUM
    
    sip1 = inc_ip(INITIAL_SIP1, ip_iteration)
    dip1 = inc_ip(INITIAL_DIP1, ip_iteration)
    auth1 = dip1
    auth2 = sip1
    upfIP1 = inc_ip(INITIAL_UPFIP1, ip_iteration)
    gnbIP1 = inc_ip(INITIAL_GNBIP1, ip_iteration)
      # æ•°å€¼å­—æ®µ+1é€’å¢
    imsi1 = inc_int(INITIAL_IMSI1, iteration)
    imei14 = inc_int(INITIAL_IMEI14, iteration)
    gpsi1 = inc_int(INITIAL_GPSI1, iteration)
    PduAddr1 = inc_ip(INITIAL_PDUADDR1, iteration)
    tac1 = inc_int(INITIAL_TAC1, iteration % TAC_NUM)  # ä½¿ç”¨TAC_NUMè¿›è¡Œå¾ªç¯
    cgi1 = inc_int(INITIAL_CGI1, iteration)
    upTEID1 = inc_hex(INITIAL_UPTEID1, iteration)
    dnTEID1 = inc_hex(INITIAL_DNTEID1, iteration)
    
    # DNNç‰¹æ®Šå¤„ç†
    try:
        numeric_part = int(''.join(filter(str.isdigit, INITIAL_DNN1)))
        prefix = ''.join(filter(str.isalpha, INITIAL_DNN1))
        dnn1 = f"{prefix}{numeric_part + iteration:09d}"
    except:
        dnn1 = INITIAL_DNN1
    
    # ç«¯å£+3é€’å¢ï¼Œå¾ªç¯å¤„ç†
    sport_iteration = (iteration * 3) % SPORT_NUM
    sport1 = inc_port(INITIAL_SPORT1, sport_iteration)
    sport2 = sport1 + 1  # sport1 + 1
    sport3 = sport1 + 2  # sport1 + 2

# å…¼å®¹æ€§å˜é‡å·²ç§»é™¤ï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨æ–°å˜é‡å
CLIENT_IP_OLD = "121.1.1.10"
SERVER_IP_OLD = "123.1.1.10"
SV_DEFAULT = "00"
RE_IMSI = re.compile(r'imsi-\d+')

def luhn_checksum(numstr: str) -> int:
    """è®¡ç®—Luhnæ ¡éªŒå’Œï¼ˆç”¨äºIMEIç¬¬15ä½ï¼‰"""
    digits = [int(d) for d in numstr]
    oddsum = sum(digits[-1::-2])
    evensum = sum(sum(divmod(2 * d, 10)) for d in digits[-2::-2])
    return (oddsum + evensum) % 10

def imei14_to_imei15(imei14: str) -> str:
    """14ä½IMEIè½¬15ä½IMEIï¼ˆåŠ Luhnæ ¡éªŒï¼‰"""
    check = luhn_checksum(imei14 + '0')
    check_digit = (10 - check) % 10
    return imei14 + str(check_digit)

def imei14_to_imeisv(imei14: str, sv: str = SV_DEFAULT) -> str:
    """14ä½IMEIè½¬16ä½IMEISV"""
    return imei14 + sv

# ç¤ºä¾‹å˜é‡èµ‹å€¼ï¼ˆå»é™¤é‡å¤ï¼‰
imei15 = imei14_to_imei15(imei14)
pei1 = imei14_to_imeisv(imei14)

def update_target_fields():
    """æ›´æ–°TARGET_FIELDSï¼Œä½¿ç”¨å½“å‰å˜é‡å€¼"""
    return {
        "supi": f"imsi-{imsi1}",
        "pei": f"imeisv-{imei14_to_imeisv(imei14)}",
        "gpsi": f"msisdn-{gpsi1}",    
        "dnn": dnn1,
        "tac": tac1,
        "nrCellId": cgi1,
        "smContextStatusUri": f"http://{sip1}/ntf-service/v1/nsmf-notify/0/pdusession-smcontextsts"    }

MODIFY_PATH_PREFIX = "/nsmf-pdusession/v1/sm-contexts/"
MODIFY_PATH_SUFFIX = "-5/modify"
LOCATION_HEADER_PREFIX = "http://123.1.1.10/nsmf-pdusession/v1/sm-contexts/"
LOCATION_HEADER_SUFFIX = "-5"

def inc_ip(ip: str, step: int = 1) -> str:
    """IPè‡ªå¢"""
    parts = list(map(int, ip.split('.')))
    val = (parts[0]<<24) + (parts[1]<<16) + (parts[2]<<8) + parts[3] + step
    return f"{(val>>24)&0xFF}.{(val>>16)&0xFF}.{(val>>8)&0xFF}.{val&0xFF}"

def inc_int(val: str, step: int = 1) -> str:
    return str(int(val) + step)

def inc_hex(val: int, step: int = 1) -> int:
    return val + step

def inc_port(port: int, step: int = 1) -> int:
    """ç«¯å£è‡ªå¢ï¼Œç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…"""
    new_port = port + step
    # ç¡®ä¿ç«¯å£åœ¨æœ‰æ•ˆèŒƒå›´å†… (1-65535)
    if new_port > 65535:
        new_port = 1024 + (new_port - 65536)  # å›ç»•åˆ°ç”¨æˆ·ç«¯å£èŒƒå›´
    return new_port

def update_port_variables(step: int = 1):
    """æ›´æ–°å…¨å±€ç«¯å£å˜é‡"""
    global sport1, sport2, sport3
    sport1 = inc_port(sport1, step)
    sport2 = inc_port(sport2, step)
    sport3 = inc_port(sport3, step)
    # ç§»é™¤é‡å¤çš„PORT_MAPPINGæ›´æ–°ï¼Œæ”¹ç”¨åŠ¨æ€å‡½æ•°

class HTTP2FrameHeader(Packet):
    name = "HTTP2FrameHeader"
    fields_desc = [
        BitField("length", 0, 24),
        ByteField("type", 0),
        ByteField("flags", 0),
        BitField("reserved", 0, 1),
        BitField("stream_id", 0, 31)
    ]

def extract_http2_frames(raw: bytes) -> List[Dict[str, Any]]:
    """æå–HTTP2å¸§"""
    offset = 0
    frames = []
    while offset + 9 <= len(raw):
        frame_header = HTTP2FrameHeader(raw[offset:offset+9])
        frame_len = frame_header.length
        frame_end = min(offset + 9 + frame_len, len(raw))
        frame_data = raw[offset+9:frame_end]
        frames.append({
            'offset': offset,
            'header': frame_header,
            'type': frame_header.type,
            'data': frame_data,
            'end': frame_end
        })
        offset = frame_end
    return frames

def process_http2_headers_frame(frame_data, pkt_idx=None, new_content_length=None):
    try:
        decoder = Decoder()
        headers = decoder.decode(frame_data)
        new_headers = []
        modified = False
        for name, value in headers:
            if name.lower() == "content-length":
                continue
            orig_type = type(value)
            # å…¶å®ƒå­—æ®µæ­£å¸¸å¤„ç†
            if pkt_idx == 11 and name.lower() == ":authority":
                value = auth1
                modified = True
            if pkt_idx == 45 and name.lower() == "location":
                # å…¼å®¹bytes/bytearray/memoryview
                if isinstance(value, (bytes, bytearray, memoryview)):
                    value = value.tobytes() if isinstance(value, memoryview) else bytes(value)
                    value = value.decode(errors='ignore')
                value = str(value).replace("123.1.1.10", auth1)
                modified = True
                if orig_type in (bytes, bytearray, memoryview):
                    value = value.encode()
            if pkt_idx == 46 and name.lower() == ":authority":
                value = auth2
                modified = True
            if pkt_idx == 48 and name.lower() == ":authority":
                value = auth1
                modified = True
            if pkt_idx == 46 and name.lower() == ":path":
                if isinstance(value, (bytes, bytearray, memoryview)):
                    value = value.tobytes() if isinstance(value, memoryview) else bytes(value)
                    value = value.decode(errors='ignore')
                value = re.sub(r'imsi-\d+', f'imsi-{imsi1}', str(value))
                modified = True
                if orig_type in (bytes, bytearray, memoryview):
                    value = value.encode()
            if pkt_idx == 48 and name.lower() == ":path":
                if isinstance(value, (bytes, bytearray, memoryview)):
                    value = value.tobytes() if isinstance(value, memoryview) else bytes(value)
                    value = value.decode(errors='ignore')
                value = re.sub(r'imsi-\d+', f'imsi-{imsi1}', str(value))
                modified = True
                if orig_type in (bytes, bytearray, memoryview):
                    value = value.encode()
            new_headers.append((name, value))
        if new_content_length is not None:
            new_headers.append(("content-length", str(new_content_length)))
        encoder = Encoder()
        new_data = encoder.encode(new_headers)
        return new_data
    except Exception as e:
        return frame_data

def modify_json_data(payload, fields):
    try:
        if not payload.strip():
            return None
        data = json.loads(payload)
        modified = False
        def recursive_modify(obj, modifications):
            nonlocal modified
            if isinstance(obj, dict):
                for key, value in obj.items():
                    lkey = key.lower()
                    # ç‰¹æ®Šå¤„ç†smContextStatusUriå­—æ®µï¼Œæ›¿æ¢URLä¸­çš„hostéƒ¨åˆ†
                    if lkey == "smcontextstatusuri" and isinstance(value, str):
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢URLä¸­çš„hostéƒ¨åˆ†ä¸ºsip1
                        new_value = re.sub(r'http://[^/]+', f'http://{sip1}', value)
                        if new_value != value:
                            obj[key] = new_value
                            modified = True
                    else:
                        # åŸæœ‰çš„å­—æ®µåŒ¹é…é€»è¾‘
                        for target in modifications:
                            if target.lower() == lkey:
                                obj[key] = modifications[target]
                                modified = True
                                break
                    if isinstance(value, (dict, list)):
                        recursive_modify(value, modifications)
            elif isinstance(obj, list):
                for item in obj:
                    if isinstance(item, (dict, list)):
                        recursive_modify(item, modifications)
        recursive_modify(data, fields)
        return json.dumps(data, separators=(',', ':')).encode() if modified else None
    except Exception as e:
        return None

def process_http2_data_frame(frame_data, fields):
    if b"--++Boundary" in frame_data:
        parts = re.split(br'(--\+\+Boundary)', frame_data)
        for i in range(len(parts)):
            if parts[i] == b"--++Boundary" and i + 1 < len(parts):
                if b"Content-Type:application/json" in parts[i + 1]:
                    segments = parts[i + 1].split(b"\r\n\r\n", 1)
                    if len(segments) == 2:
                        json_part = segments[1]
                        modified = modify_json_data(json_part, fields)
                        if modified:
                            parts[i + 1] = segments[0] + b"\r\n\r\n" + modified
        return b''.join(parts)
    else:
        modified = modify_json_data(frame_data, fields)
        return modified if modified else frame_data

def batch_collect_targets(original_packets):
    pkt_http2_info = []
    for idx, pkt in enumerate(original_packets):
        pkt_info = []
        if pkt.haslayer(TCP) and pkt.haslayer(Raw):
            raw = bytes(pkt[Raw].load)
            
            # éªŒè¯å¸§ç»“æ„
            if not validate_http2_frame_structure(raw, idx):
                print(f"[é”™è¯¯] ç¬¬{idx+1}å·æŠ¥æ–‡çš„HTTP/2å¸§ç»“æ„å¼‚å¸¸")
            
            frames = extract_http2_frames(raw)
            headers_count = 0  # è·Ÿè¸ªHEADERSå¸§çš„æ•°é‡
            for fidx, frame in enumerate(frames):
                frame_type = frame['type']
                frame_data = frame['data']
                if frame_type == 0x1:  # HEADERS
                    headers_count += 1
                    pkt_info.append({
                        'frame_idx': fidx,
                        'headers_index': headers_count,  # è¿™æ˜¯ç¬¬å‡ ä¸ªHEADERSå¸§
                        'type': 'headers',
                        'data': frame_data,
                        'frame': frame,
                    })
                elif frame_type == 0x0:  # DATA
                    pkt_info.append({
                        'frame_idx': fidx,
                        'type': 'data',
                        'data': frame_data,
                        'frame': frame,
                    })
        pkt_http2_info.append(pkt_info)
    return pkt_http2_info

def batch_modify_targets(pkt_http2_info, target_fields):
    all_new_payloads = []
    for pkt_idx, pkt_info in enumerate(pkt_http2_info):
        if not pkt_info:
            all_new_payloads.append(None)
            continue
          # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if pkt_idx in (11, 46, 48):  # åªå¯¹å…³é”®æŠ¥æ–‡è°ƒè¯•
            debug_packet_frames(pkt_idx, pkt_info)
        
        new_frames = []
        # å…ˆå¤„ç†DATAå¸§ï¼Œæ‹¿åˆ°æ–°å†…å®¹é•¿åº¦
        new_content_length = None
        data_frame_new_data = None
          # ç¡®å®šæ˜¯å¦æœ‰DATAå¸§å¹¶å¤„ç†
        for entry in pkt_info:
            if entry['type'] == 'data':
                # å…³é”®æŠ¥æ–‡DATAå¸§ç²¾ç¡®å¤„ç†
                if pkt_idx in (11, 46, 48):  # å…³é”®æŠ¥æ–‡12ã€47ã€49
                    data_frame_new_data = process_http2_data_frame_precise(pkt_idx, entry['data'], target_fields)
                else:
                    data_frame_new_data = process_http2_data_frame(entry['data'], target_fields)
                
                if data_frame_new_data:
                    new_content_length = len(data_frame_new_data)
                    entry['__new_data'] = data_frame_new_data
        
        # é‡å»ºå„å¸§å†…å®¹
        for entry in pkt_info:
            frame = entry['frame']
            if entry['type'] == 'headers':
                # å…³é”®æŠ¥æ–‡å¤´éƒ¨çš„ä¸¥æ ¼é‡å»º
                if pkt_idx in (11, 45, 46, 48):  # 12ã€46ã€47ã€49å·æŠ¥æ–‡
                    new_frame_data = process_http2_headers_frame_precise(pkt_idx, new_content_length)
                    if new_frame_data is None:
                        # å…œåº•ï¼šç”¨é€šç”¨å¤„ç†
                        new_frame_data = process_http2_headers_frame(entry['data'], pkt_idx=pkt_idx, new_content_length=new_content_length)
                else:
                    new_frame_data = process_http2_headers_frame(entry['data'], pkt_idx=pkt_idx, new_content_length=new_content_length)
                
                frame_header = frame['header']
                frame_header.length = len(new_frame_data)
                new_frames.append(frame_header.build() + new_frame_data)
            elif entry['type'] == 'data':
                # ç›´æ¥ç”¨å·²å¤„ç†çš„æ–°DATAå¸§å†…å®¹
                if '__new_data' in entry:
                    new_frame_data = entry['__new_data']
                else:
                    new_frame_data = process_http2_data_frame(entry['data'], target_fields)
                frame_header = frame['header']
                frame_header.length = len(new_frame_data)
                new_frames.append(frame_header.build() + new_frame_data)
        new_payload = b''.join(new_frames) if new_frames else None
        all_new_payloads.append(new_payload)
    return all_new_payloads

def update_ip(pkt):
    """æ›´æ–°IPåœ°å€å’ŒTCPç«¯å£"""
    if pkt.haslayer(IP):
        if pkt[IP].src == CLIENT_IP_OLD:
            pkt[IP].src = sip1
        elif pkt[IP].src == SERVER_IP_OLD:
            pkt[IP].src = dip1
        if pkt[IP].dst == CLIENT_IP_OLD:
            pkt[IP].dst = sip1
        elif pkt[IP].dst == SERVER_IP_OLD:
            pkt[IP].dst = dip1        # ä½¿ç”¨åŠ¨æ€ç«¯å£æ˜ å°„
        if pkt.haslayer(TCP):
            port_mapping = get_port_mapping()  # è·å–å½“å‰æ˜ å°„
            
            # æ›¿æ¢æºç«¯å£
            if pkt[TCP].sport in port_mapping:
                pkt[TCP].sport = port_mapping[pkt[TCP].sport]
            
            # æ›¿æ¢ç›®çš„ç«¯å£
            if pkt[TCP].dport in port_mapping:
                pkt[TCP].dport = port_mapping[pkt[TCP].dport]

def update_packets(original_packets, all_new_payloads):
    seq_diff = {}
    modified_packets = []
    for idx, pkt in enumerate(original_packets):
        pkt = copy.deepcopy(pkt)
        update_ip(pkt)
        if pkt.haslayer(TCP) and pkt.haslayer(Raw) and all_new_payloads[idx]:
            flow = (pkt[IP].src, pkt[IP].dst, pkt[TCP].sport, pkt[TCP].dport)
            rev_flow = (pkt[IP].dst, pkt[IP].src, pkt[TCP].dport, pkt[TCP].sport)
            seq_diff.setdefault(flow, 0)
            seq_diff.setdefault(rev_flow, 0)
            raw = bytes(pkt[Raw].load)
            new_payload = all_new_payloads[idx]
            diff = len(new_payload) - len(raw)
            pkt[Raw].load = new_payload
            # ç»Ÿä¸€ç”¨ç´¯è®¡diffè¡¨è°ƒæ•´seq/ack
            pkt[TCP].seq = pkt[TCP].seq + seq_diff[flow]
            if pkt[TCP].flags & 0x10 and hasattr(pkt[TCP], 'ack'):
                pkt[TCP].ack = pkt[TCP].ack + seq_diff[rev_flow]
            seq_diff[flow] += diff
            if hasattr(pkt[IP], 'chksum'):
                del pkt[IP].chksum
            if hasattr(pkt[TCP], 'chksum'):
                del pkt[TCP].chksum
            if hasattr(pkt[IP], 'len'):
                del pkt[IP].len
            pkt.wirelen = len(pkt)
            pkt.caplen = pkt.wirelen
        modified_packets.append(pkt)
    return modified_packets

def process_http2_headers_frame_precise(pkt_idx, new_content_length=None):
    """
    é’ˆå¯¹å…³é”®æŠ¥æ–‡ï¼ˆ12ã€46ã€47ã€49ï¼‰ä¸¥æ ¼é‡å»ºHTTP/2å¤´éƒ¨ï¼Œé¡ºåºå’Œå†…å®¹å‡†ç¡®ã€‚
    """
    encoder = Encoder()
    # 12ã€46ã€47ã€49ä¸ºWiresharkåºå·ï¼ŒPythonä¸‹ä»0è®¡æ•°ï¼Œéœ€-1
    if pkt_idx == 11:  # ç¬¬12ä¸ªæŠ¥æ–‡
        headers = [
            (":method", "POST"),
            (":scheme", "http"),
            (":authority", auth1),
            (":path", "/nsmf-pdusession/v1/sm-contexts"),
            ("content-type", "multipart/related; boundary=++Boundary"),
            ("content-length", str(new_content_length) if new_content_length else "0"),
            ("accept", "application/json"),
            ("user-agent", "AMF"),
        ]
        return encoder.encode(headers)
    elif pkt_idx == 45:  # ç¬¬46ä¸ªæŠ¥æ–‡
        headers = [
            (":status", "201"),
            ("content-type", "multipart/related; boundary=++Boundary"),
            ("location", f"http://{auth1}/nsmf-pdusession/v1/sm-contexts/{imsi1}-5"),
            ("date", "Wed, 22 May 2025 02:48:05 GMT"),
            ("content-length", str(new_content_length) if new_content_length else "0"),
        ]
        return encoder.encode(headers)
    elif pkt_idx == 46:  # ç¬¬47ä¸ªæŠ¥æ–‡
        headers = [
            (":method", "POST"),
            (":scheme", "http"),
            (":authority", auth2),
            (":path", f"/namf-comm/v1/ue-contexts/imsi-{imsi1}/n1-n2-messages"),
            ("content-type", "multipart/related; boundary=++Boundary"),
            ("content-length", str(new_content_length) if new_content_length else "0"),
            ("user-agent", "SMF"),
        ]
        return encoder.encode(headers)
    elif pkt_idx == 48:  # ç¬¬49ä¸ªæŠ¥æ–‡
        headers = [
            (":method", "POST"),
            (":scheme", "http"),
            (":authority", auth1),
            (":path", f"/nsmf-pdusession/v1/sm-contexts/imsi-{imsi1}-5/modify"),
            ("content-type", "multipart/related; boundary=++Boundary"),
            ("content-length", str(new_content_length) if new_content_length else "0"),
            ("accept", "application/json"),
            ("user-agent", "SMF"),
        ]
        return encoder.encode(headers)
    else:
        return None

# å‡½æ•°å·²åˆ é™¤ï¼Œå› ä¸ºæŠ¥æ–‡ä¸­åªæœ‰ä¸€ä¸ªHEADERSå¸§

def process_http2_data_frame_precise(pkt_idx, frame_data, fields):
    """
    é’ˆå¯¹å…³é”®æŠ¥æ–‡ï¼ˆ12ã€47ã€49ï¼‰DATAå¸§çš„ç²¾ç¡®å¤„ç†ï¼Œä¸¥æ ¼ä¿æŒMIMEç»“æ„
    """
    # åªå¤„ç†å«boundaryçš„multipart
    if pkt_idx in (11, 46, 48) and b"--++Boundary" in frame_data:
        # å®Œå…¨é‡å»ºMIMEç»“æ„ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
        return rebuild_mime_structure(frame_data, fields, pkt_idx)
    else:
        # å¦‚æœä¸æ˜¯multipartæ ¼å¼ï¼Œä½¿ç”¨æ ‡å‡†å¤„ç†
        return process_http2_data_frame(frame_data, fields)

def rebuild_mime_structure(frame_data, fields, pkt_idx):
    """é‡å»ºå®Œæ•´çš„MIMEç»“æ„ï¼Œç¡®ä¿èƒ½æ­£ç¡®è§£æ"""
    
    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯æŠ¥æ–‡47ï¼Œå…ˆåœ¨å®Œæ•´MIMEæ•°æ®ä¸­ä¿®æ”¹gTPTunnel
    if pkt_idx == 46:  # ç¬¬47å·æŠ¥æ–‡
        frame_data = modify_packet47_gtp_in_full_mime(frame_data)
    
    # è§£æåŸå§‹MIMEç»“æ„
    parts = frame_data.split(b'--++Boundary')
    mime_parts = []
    
    for i, part in enumerate(parts[1:], 1):  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºéƒ¨åˆ†
        if not part or part == b'--\r\n':
            continue
            
        if b'\r\n\r\n' in part:
            headers_section, body_section = part.split(b'\r\n\r\n', 1)
            
            # ç§»é™¤å°¾éƒ¨çš„è¾¹ç•Œæ ‡è®°
            if b'\r\n--' in body_section:
                body_section = body_section.split(b'\r\n--', 1)[0]
            
            # å¦‚æœæ˜¯JSONéƒ¨åˆ†ï¼Œå¤„ç†å­—æ®µä¿®æ”¹
            if b'Content-Type:application/json' in headers_section:
                # ç¡®ä¿æœ‰Content-Idå¤´
                if b'Content-Id:' not in headers_section:
                    content_id = "PduSessEstReq" if pkt_idx == 11 else f"Part{i}"
                    headers_section += f"\r\nContent-Id:{content_id}".encode()
                # ä¿®æ”¹JSONå†…å®¹
                modified_json = modify_json_data(body_section, fields)
                if modified_json:
                    body_section = modified_json
            else:
                # éJSONéƒ¨åˆ†ï¼Œç¡®ä¿æœ‰Content-Id
                if b'Content-Id:' not in headers_section:
                    content_id = f"Part{i}"
                    headers_section += f"\r\nContent-Id:{content_id}".encode()
                # å¤„ç†äºŒè¿›åˆ¶éƒ¨åˆ†çš„MIMEç»“æ„ï¼ˆé’ˆå¯¹ç¬¬47ã€49æŠ¥æ–‡çš„ç¬¬2ä¸ªéƒ¨åˆ†ï¼‰
                if (pkt_idx == 46 or pkt_idx == 48) and i == 2:  # ç¬¬2ä¸ªéƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯äºŒè¿›åˆ¶éƒ¨åˆ†ï¼‰
                    # ä¼ é€’å®Œæ•´çš„frame_dataä½œä¸ºfull_mime_dataå‚æ•°
                    body_section = modify_binary_elements(body_section, pkt_idx, frame_data)
            
            # é‡å»ºè¿™ä¸ªMIMEéƒ¨åˆ†
            rebuilt_part = headers_section + b'\r\n\r\n' + body_section
            mime_parts.append(rebuilt_part)
        else:
            # å¤„ç†æ²¡æœ‰åˆ†éš”ç¬¦çš„éƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯åªæœ‰å¤´éƒ¨æ²¡æœ‰ä½“çš„éƒ¨åˆ†ï¼‰
            headers_section = part
            
            # ç§»é™¤å°¾éƒ¨çš„è¾¹ç•Œæ ‡è®°
            if b'\r\n--' in headers_section:
                headers_section = headers_section.split(b'\r\n--', 1)[0]
            
            # ç¡®ä¿æœ‰Content-Idå¤´
            if b'Content-Id:' not in headers_section:
                content_id = f"Part{i}"
                headers_section += f"\r\nContent-Id:{content_id}".encode()
            
            # é‡å»ºè¿™ä¸ªMIMEéƒ¨åˆ†ï¼ˆæ·»åŠ åˆ†éš”ç¬¦å’Œç©ºä½“ï¼‰
            rebuilt_part = headers_section + b'\r\n\r\n'
            mime_parts.append(rebuilt_part)
    
    # é‡å»ºå®Œæ•´çš„multipartå†…å®¹
    result = b'--++Boundary'
    for part in mime_parts:
        result += part + b'\r\n--++Boundary'
    result += b'--\r\n'
    
    return result

def process_one_iteration(original_packets, iteration):
    """å¤„ç†å•æ¬¡è¿­ä»£çš„æ‰€æœ‰æ•°æ®åŒ…"""
    # æ›´æ–°å˜é‡
    update_batch_variables(iteration)
    target_fields = update_target_fields()
    
    # å¤„ç†æ•°æ®åŒ…
    pkt_http2_info = batch_collect_targets(original_packets)
    all_new_payloads = batch_modify_targets(pkt_http2_info, target_fields)
    new_packets = update_packets(original_packets, all_new_payloads)
    
    return new_packets

def write_pcap_batch(packets, filename):
    """å†™å…¥PCAPæ–‡ä»¶å¹¶å›æ”¶å†…å­˜"""
    try:
        # ä¿®å¤æ•°æ®åŒ…é“¾è·¯å±‚ç±»å‹é—®é¢˜
        fixed_packets = []
        for pkt in packets:
            if pkt.__class__.__name__ == 'Raw':
                # å¦‚æœæ˜¯RawåŒ…ï¼ŒåŒ…è£…ä¸ºEtherå¸§ä»¥é¿å…å†™å…¥é”™è¯¯
                eth_pkt = Ether()/pkt
                fixed_packets.append(eth_pkt)
            else:
                fixed_packets.append(pkt)
        
        wrpcap(filename, fixed_packets)
        print(f"æˆåŠŸå†™å…¥PCAPæ–‡ä»¶: {filename}, åŒ…å« {len(fixed_packets)} ä¸ªæ•°æ®åŒ…")
        
        # æ¸…ç†å†…å­˜
        del fixed_packets
        del packets
        import gc
        gc.collect()
        
    except Exception as e:
        print(f"å†™å…¥PCAPæ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")

def main_batch_loop(
    pcap_in,
    pcap_out,
    total_iterations=1000,
    pcap_write_interval=200000,
    max_workers=6
):
    """ä¸»å¾ªç¯æ‰¹é‡å¤„ç†å‡½æ•°"""
    print("=== N11æ‰¹é‡å¾ªç¯å¤„ç†å¼€å§‹ ===")
    print(f"è¾“å…¥æ–‡ä»¶: {pcap_in}")
    print(f"è¾“å‡ºæ–‡ä»¶å‰ç¼€: {pcap_out}")
    print(f"æ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
    print(f"PCAPå†™å…¥é—´éš”: {pcap_write_interval}")
    print(f"çº¿ç¨‹æ•°: {max_workers}")
    
    try:
        # è¯»å–åŸå§‹PCAP
        print("æ­£åœ¨è¯»å–åŸå§‹PCAPæ–‡ä»¶...")
        original_packets = rdpcap(pcap_in)
        print(f"æˆåŠŸè¯»å– {len(original_packets)} ä¸ªæ•°æ®åŒ…")
        
        all_packets = []
        pcap_file_count = 0
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            for i in tqdm(range(total_iterations), desc="å¤„ç†è¿›åº¦"):
                # æäº¤å¤„ç†ä»»åŠ¡
                future = executor.submit(process_one_iteration, copy.deepcopy(original_packets), i)
                batch_packets = future.result()
                all_packets.extend(batch_packets)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å†™å…¥PCAP
                if (i + 1) % pcap_write_interval == 0 or (i + 1) == total_iterations:
                    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                    base_name, ext = os.path.splitext(pcap_out)
                    output_filename = f"{base_name}_{pcap_file_count + 1:03d}{ext}"
                    
                    # å†™å…¥PCAPæ–‡ä»¶
                    write_pcap_batch(all_packets, output_filename)
                    
                    # é‡ç½®ç´¯ç§¯åŒ…åˆ—è¡¨
                    all_packets = []
                    pcap_file_count += 1
                    
                    print(f"å®Œæˆç¬¬ {pcap_file_count} ä¸ªPCAPæ–‡ä»¶ï¼ŒåŒ…å« {min(pcap_write_interval, total_iterations - i + pcap_write_interval - 1)} æ¬¡è¿­ä»£")
        
        print(f"=== æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {pcap_file_count} ä¸ªPCAPæ–‡ä»¶ ===")
        
    except Exception as e:
        print(f"æ‰¹é‡å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def debug_packet_frames(pkt_idx, pkt_info):
    """è°ƒè¯•å‡½æ•°ï¼šç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸­çš„è¾“å‡ºå†²çª"""
    # ç§»é™¤è°ƒè¯•è¾“å‡ºä»¥é¿å…å¤šè¿›ç¨‹ç¯å¢ƒä¸­çš„æ··ä¹±è¾“å‡º
    pass

def validate_http2_frame_structure(raw_data, pkt_idx):
    """ç®€åŒ–çš„HTTP/2å¸§ç»“æ„éªŒè¯"""
    frames = extract_http2_frames(raw_data)
    return len(frames) > 0

def modify_packet47_gtp_in_full_mime(frame_data):
    """
    ä¸“é—¨å¤„ç†ç¬¬47ä¸ªæŠ¥æ–‡çš„gTPTunnelä¿®æ”¹
    åœ¨å®Œæ•´çš„MIMEæ•°æ®ä¸­æŸ¥æ‰¾å¹¶ä¿®æ”¹gTPTunnelå­—æ®µ
    """
    global upfIP1, upTEID1
    
    # ç›®æ ‡IPå’ŒTEID
    original_ip = bytes([123, 1, 1, 20])  # 123.1.1.20
    original_teid = bytes([0x00, 0x1e, 0x84, 0x80])  # 0x1e8480
    
    modified_data = bytearray(frame_data)
    modifications_count = 0
    
    # åœ¨å®Œæ•´æ•°æ®ä¸­æŸ¥æ‰¾gTPTunnel
    ip_pos = modified_data.find(original_ip)
    if ip_pos >= 0:
        # æ£€æŸ¥TEID
        teid_pos = ip_pos + 4
        if teid_pos + 4 <= len(modified_data):
            found_teid = bytes(modified_data[teid_pos:teid_pos+4])
            if found_teid == original_teid:
                # ä¿®æ”¹IPåœ°å€
                new_ip_parts = [int(x) for x in upfIP1.split('.')]
                modified_data[ip_pos:ip_pos+4] = new_ip_parts
                upfIP1 = inc_ip(upfIP1)
                modifications_count += 1
                
                # ä¿®æ”¹TEID
                new_teid_bytes = upTEID1.to_bytes(4, 'big')
                modified_data[teid_pos:teid_pos+4] = new_teid_bytes
                upTEID1 = inc_hex(upTEID1)
                modifications_count += 1
                
                return bytes(modified_data)
    
    return frame_data

def modify_binary_elements(frame_data, pkt_idx, full_mime_data=None):
    """
    ä¿®æ”¹äºŒè¿›åˆ¶å½¢å¼çš„MIMEç»“æ„ä¸­çš„ç‰¹å®šå­—æ®µ - åŸºäºå®é™…gTPTunnelå­—æ®µä½ç½®
    """
    global PduAddr1, dnn1, upfIP1, upTEID1, gnbIP1, dnTEID1
    
    modified_data = bytearray(frame_data)  # ä½¿ç”¨bytearrayä¾¿äºä¿®æ”¹
    modifications_count = 0
    
    # æŠ¥æ–‡47: ä¿®æ”¹PDU addressã€DNNã€gTPTunnel
    if pkt_idx == 46:
        # 1. æŸ¥æ‰¾å¹¶ä¿®æ”¹PDU address (element ID=0x29)
        pdu_patterns = [
            b'\x29\x05\x01',      # æ ‡å‡†: ID=0x29, len=5, type=IPv4
            b'\x29\x04',          # ç®€åŒ–: ID=0x29, len=4
            b'\x29',              # æœ€åŸºæœ¬: åªæŸ¥æ‰¾ID
        ]
        
        pdu_addr_found = False
        for i, pattern in enumerate(pdu_patterns):
            pdu_pos = modified_data.find(pattern)
            if pdu_pos >= 0:
                # æ ¹æ®ä¸åŒæ¨¡å¼ç¡®å®šIPåœ°å€ä½ç½®
                if i == 0:  # å®Œæ•´æ¨¡å¼
                    ip_pos = pdu_pos + 3
                elif i == 1:  # ç®€åŒ–æ¨¡å¼
                    ip_pos = pdu_pos + 2
                else:  # åŸºæœ¬æ¨¡å¼ï¼Œéœ€è¦è·³è¿‡é•¿åº¦å­—èŠ‚
                    if pdu_pos + 1 < len(modified_data):
                        length = modified_data[pdu_pos + 1]
                        if length >= 4:
                            ip_pos = pdu_pos + 2 + (length - 4)  # å‡è®¾IPåœ¨å­—æ®µæœ«å°¾
                        else:
                            continue
                    else:
                        continue
                
                # ä¿®æ”¹IPåœ°å€
                if ip_pos + 4 <= len(modified_data):
                    new_ip_parts = [int(x) for x in PduAddr1.split('.')]
                    
                    # éªŒè¯æ–°IPåœ°å€çš„åˆç†æ€§
                    if all(0 <= part <= 255 for part in new_ip_parts):
                        modified_data[ip_pos:ip_pos+4] = new_ip_parts
                        PduAddr1 = inc_ip(PduAddr1)
                        modifications_count += 1
                        pdu_addr_found = True
                        break
                else:
                    continue
        
        # 2. æŸ¥æ‰¾å¹¶ä¿®æ”¹DNN (element ID=0x25)
        dnn_pos = modified_data.find(b'\x25')
        if dnn_pos >= 0 and dnn_pos + 1 < len(modified_data):
            old_length = modified_data[dnn_pos + 1]
            
            # è®¡ç®—åŸDNNå­—æ®µçš„ç»“æŸä½ç½®
            dnn_data_start = dnn_pos + 2
            dnn_data_end = dnn_data_start + old_length
            
            if dnn_data_end <= len(modified_data):
                # å‡†å¤‡æ–°çš„DNNæ•°æ®
                new_dnn_bytes = dnn1.encode('utf-8')
                new_length = 13  # å›ºå®šé•¿åº¦13
                
                # æ„å»ºæ–°çš„DNNå­—æ®µ: length + actual_length + data
                if len(new_dnn_bytes) <= new_length - 1:  # é¢„ç•™1å­—èŠ‚ç»™å®é™…é•¿åº¦
                    new_dnn_field = bytes([new_length, len(new_dnn_bytes)]) + new_dnn_bytes
                    
                    # æ›¿æ¢DNNå­—æ®µ (ä¿ç•™element ID)
                    new_data = (modified_data[:dnn_pos+1] + 
                               new_dnn_field + 
                               modified_data[dnn_data_end:])
                    modified_data = bytearray(new_data)
                    
                    # é€’å¢DNN
                    try:
                        numeric_part = int(''.join(filter(str.isdigit, dnn1)))
                        prefix = ''.join(filter(str.isalpha, dnn1))
                        dnn1 = f"{prefix}{numeric_part + 1:09d}"  # ä¿æŒ9ä½æ•°å­—
                    except:
                        pass
                    modifications_count += 1
        
        # 3. ç¬¬47å·æŠ¥æ–‡çš„gTPTunnelåœ¨rebuild_mime_structureä¸­å·²ç»å¤„ç†è¿‡äº†
        
    # æŠ¥æ–‡49: ä¿®æ”¹gTPTunnelå­—æ®µ
    elif pkt_idx == 48:        # æŸ¥æ‰¾å¹¶ä¿®æ”¹gTPTunnelå­—æ®µï¼ˆåŸºäºå®é™…å­—æ®µä½ç½®ï¼‰
        # ç¬¬49å·æŠ¥æ–‡æŸ¥æ‰¾åŸå§‹IP: 124.1.1.3 å’Œ TEID: 0x1
        original_ip = bytes([124, 1, 1, 3])  # 124.1.1.3
        original_teid = bytes([0x00, 0x00, 0x00, 0x01])  # 0x1
        
        ip_pos = modified_data.find(original_ip)
        if ip_pos >= 0:
            # æ£€æŸ¥åé¢4å­—èŠ‚æ˜¯å¦æ˜¯åŸå§‹TEID
            teid_pos = ip_pos + 4
            if teid_pos + 4 <= len(modified_data):
                found_teid = bytes(modified_data[teid_pos:teid_pos+4])
                if found_teid == original_teid:
                    # ä¿®æ”¹IPåœ°å€
                    new_ip_parts = [int(x) for x in gnbIP1.split('.')]
                    modified_data[ip_pos:ip_pos+4] = new_ip_parts
                    gnbIP1 = inc_ip(gnbIP1)
                    modifications_count += 1
                    
                    # ä¿®æ”¹TEID
                    new_teid_bytes = dnTEID1.to_bytes(4, 'big')
                    modified_data[teid_pos:teid_pos+4] = new_teid_bytes
                    dnTEID1 = inc_hex(dnTEID1)
                    modifications_count += 1
    
    return bytes(modified_data)

def process_one_group_n11(i, orig_packets_bytes, ip_num=2000, sport_num=20000):
    """
    N16é£æ ¼çš„å•ç»„å¤„ç†å‡½æ•°ï¼Œé€‚é…N11é€»è¾‘
    åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­å¤„ç†å•æ¬¡è¿­ä»£ï¼Œé¿å…pickleå¤§å¯¹è±¡
    """
    try:
        # ååºåˆ—åŒ–åŸå§‹æ•°æ®åŒ…
        original_packets = rdpcap(orig_packets_bytes)
        
        # æ›´æ–°å˜é‡ï¼ˆåŸºäºè¿­ä»£æ¬¡æ•°ï¼‰
        update_batch_variables(i)
        target_fields = update_target_fields()
        
        # å¤„ç†æ•°æ®åŒ…
        pkt_http2_info = batch_collect_targets(original_packets)
        all_new_payloads = batch_modify_targets(pkt_http2_info, target_fields)
        new_packets = update_packets(original_packets, all_new_payloads)
        
        # åºåˆ—åŒ–ç»“æœï¼Œé¿å…å¤æ‚å¯¹è±¡ä¼ é€’
        return [bytes(pkt) for pkt in new_packets]
        
    except Exception as e:
        print(f"å¤„ç†ç»„ {i} æ—¶å‡ºé”™: {e}")
        return []

def async_write_pcap(filename, packets):
    """å¼‚æ­¥å†™å…¥PCAPæ–‡ä»¶ï¼Œå¸¦å†…å­˜æ¸…ç†"""
    try:
        # å°†å­—èŠ‚æ•°æ®é‡æ–°è½¬æ¢ä¸ºEtheråŒ…
        fixed_packets = []
        for pkt_bytes in packets:
            try:
                pkt = Ether(pkt_bytes)
                fixed_packets.append(pkt)
            except:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ä½œä¸ºRawåŒ…å¤„ç†
                pkt = Ether()/Raw(pkt_bytes)
                fixed_packets.append(pkt)
        
        wrpcap(filename, fixed_packets)
        print(f"âœ… æˆåŠŸå†™å…¥: {filename} ({len(fixed_packets)} åŒ…)")
        
        # ä¸»åŠ¨æ¸…ç†å†…å­˜
        del fixed_packets
        del packets
        gc.collect()
        
    except Exception as e:
        print(f"âŒ å†™å…¥å¤±è´¥: {filename}, é”™è¯¯: {e}")

def async_write_pcap_fixed(filename, packets):
    fixed_packets = []
    packets_copy = None
    try:
        packets_copy = list(packets)  # æµ…æ‹·è´
        # åˆ†æ‰¹å¤„ç†ï¼Œé”™è¯¯éš”ç¦»
        for pkt_bytes in packets_copy:
            if isinstance(pkt_bytes, bytes) and len(pkt_bytes) > 0:
                pkt = Ether(pkt_bytes)
                fixed_packets.append(pkt)
        wrpcap(filename, fixed_packets)
    finally:
        # ç¡®ä¿æ¸…ç†
        if fixed_packets:
            del fixed_packets
        if packets_copy:
            del packets_copy
        gc.collect()

def main_batch_n16_style(
    pcap_in,
    pcap_out,
    total_iterations=1000,
    pcap_write_interval=200000,
    process_workers=6,
    thread_workers=4
):
    """
    N16é£æ ¼çš„æ··åˆæ¶æ„å¤„ç†å‡½æ•°
    ProcessPoolExecutor + ThreadPoolExecutor
    """
    print("=== N11 N16é£æ ¼æ··åˆæ¶æ„å¤„ç†å¼€å§‹ ===")
    print(f"è¾“å…¥æ–‡ä»¶: {pcap_in}")
    print(f"è¾“å‡ºæ–‡ä»¶å‰ç¼€: {pcap_out}")
    print(f"æ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
    print(f"PCAPå†™å…¥é—´éš”: {pcap_write_interval}")
    print(f"è¿›ç¨‹æ± å¤§å°: {process_workers}")
    print(f"çº¿ç¨‹æ± å¤§å°: {thread_workers}")
    
    start_time = time.time()
    
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(pcap_in):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {pcap_in}")
            return
        
        # 1. ä¸´æ—¶æ–‡ä»¶åºåˆ—åŒ– (N16é£æ ¼)
        print("ğŸ”„ åºåˆ—åŒ–åŸå§‹PCAPåˆ°ä¸´æ—¶æ–‡ä»¶...")
        orig_packets = rdpcap(pcap_in)
        with tempfile.NamedTemporaryFile(delete=False) as tf:
            wrpcap(tf.name, orig_packets)
            orig_packets_bytes = tf.name
        
        print(f"ğŸ“¦ æˆåŠŸè¯»å– {len(orig_packets)} ä¸ªæ•°æ®åŒ…")
        
        # ä¸»åŠ¨é‡Šæ”¾åŸå§‹PCAPæ•°æ®
        del orig_packets
        gc.collect()
        
        # 2. è®¡ç®—æ‰¹æ¬¡åˆ†å‰²
        BATCH_SIZE = pcap_write_interval  # æ¯æ‰¹æ¬¡å¤§å°
        total_batches = total_iterations // BATCH_SIZE
        remain = total_iterations % BATCH_SIZE
        
        print(f"ğŸ“Š æ‰¹æ¬¡ä¿¡æ¯: {total_batches} ä¸ªå®Œæ•´æ‰¹æ¬¡ + {remain} ä¸ªå‰©ä½™")
        
        def get_outfile(base, idx):
            """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
            base_name, ext = os.path.splitext(base)
            return f"{base_name}_{idx+1:03d}{ext}"
        
        # 3. æ··åˆå¤„ç†æ¶æ„ (N16é£æ ¼)
        batch_idx = 0
        with ThreadPoolExecutor(max_workers=thread_workers) as file_writer:
            # å¤„ç†å®Œæ•´æ‰¹æ¬¡
            for i in range(total_batches):
                print(f"ğŸš€ å¤„ç†æ‰¹æ¬¡ {i+1}/{total_batches + (1 if remain > 0 else 0)}")
                all_modified_packets = []
                
                # ä½¿ç”¨è¿›ç¨‹æ± è¿›è¡ŒCPUå¯†é›†å‹å¤„ç†
                with ProcessPoolExecutor(max_workers=process_workers) as executor:
                    func = partial(process_one_group_n11, 
                                 orig_packets_bytes=orig_packets_bytes,
                                 ip_num=IP_NUM, sport_num=SPORT_NUM)
                    results = executor.map(func, range(i * BATCH_SIZE, (i + 1) * BATCH_SIZE))
                    
                    # æ”¶é›†å¤„ç†ç»“æœ
                    for group_bytes in tqdm(results, total=BATCH_SIZE, 
                                          desc=f"Batch {i+1}", ncols=80):
                        all_modified_packets.extend(group_bytes)
                
                # å¼‚æ­¥å†™å…¥æ–‡ä»¶ï¼ˆä¸é˜»å¡ä¸‹ä¸€æ‰¹å¤„ç†ï¼‰
                out_file = get_outfile(pcap_out, batch_idx)
                file_writer.submit(async_write_pcap, out_file, all_modified_packets)
                
                # ç«‹å³æ¸…ç†å†…å­˜
                del all_modified_packets
                gc.collect()
                batch_idx += 1
            
            # å¤„ç†å‰©ä½™ç»„
            if remain > 0:
                print(f"ğŸ”„ å¤„ç†å‰©ä½™æ‰¹æ¬¡ {batch_idx+1}/{total_batches + 1}")
                all_modified_packets = []
                
                with ProcessPoolExecutor(max_workers=process_workers) as executor:
                    func = partial(process_one_group_n11,
                                 orig_packets_bytes=orig_packets_bytes,
                                 ip_num=IP_NUM, sport_num=SPORT_NUM)
                    results = executor.map(func, range(total_batches * BATCH_SIZE, total_iterations))
                    
                    for group_bytes in tqdm(results, total=remain, 
                                          desc=f"Batch {batch_idx+1}", ncols=80):
                        all_modified_packets.extend(group_bytes)
                
                out_file = get_outfile(pcap_out, batch_idx)
                file_writer.submit(async_write_pcap, out_file, all_modified_packets)
                
                del all_modified_packets
                gc.collect()
        
        # ç­‰å¾…æ‰€æœ‰å†™ä»»åŠ¡å®Œæˆ
        file_writer.shutdown(wait=True)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(orig_packets_bytes)
        gc.collect()
        
        # ç»Ÿè®¡ä¿¡æ¯
        end_time = time.time()
        duration = end_time - start_time
        speed = total_iterations / duration if duration > 0 else 0
        
        print(f"\nâœ… N11æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å¤„ç†: {total_iterations} ç»„æ•°æ®åŒ…")
        print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f} ç§’")
        print(f"ğŸš„ å¤„ç†é€Ÿåº¦: {speed:.0f} ç»„/ç§’")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {pcap_out}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def main_batch_n16_style_optimized(
    pcap_in,
    pcap_out,
    total_iterations=1000,
    pcap_write_interval=200000,
    process_workers=6,
    thread_workers=4
):
    """
    ä¼˜åŒ–ç‰ˆN16é£æ ¼æ··åˆæ¶æ„å¤„ç†å‡½æ•°
    ä¸»è¦ä¼˜åŒ–ï¼šé¿å…è¿›ç¨‹æ± é‡å»ºå¼€é”€ï¼Œæå‡ç¬¬äºŒæ‰¹æ¬¡åŠåç»­æ‰¹æ¬¡æ€§èƒ½
    """
    print("=== N11 ä¼˜åŒ–ç‰ˆæ··åˆæ¶æ„å¤„ç†å¼€å§‹ ===")
    print(f"è¾“å…¥æ–‡ä»¶: {pcap_in}")
    print(f"è¾“å‡ºæ–‡ä»¶å‰ç¼€: {pcap_out}")
    print(f"æ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
    print(f"PCAPå†™å…¥é—´éš”: {pcap_write_interval}")
    print(f"è¿›ç¨‹æ± å¤§å°: {process_workers}")
    print(f"çº¿ç¨‹æ± å¤§å°: {thread_workers}")
    
    start_time = time.time()
    
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(pcap_in):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {pcap_in}")
            return
        
        # 1. åºåˆ—åŒ–åŸå§‹PCAPåˆ°ä¸´æ—¶æ–‡ä»¶
        print("ğŸ”„ åºåˆ—åŒ–åŸå§‹PCAPåˆ°ä¸´æ—¶æ–‡ä»¶...")
        orig_packets = rdpcap(pcap_in)
        with tempfile.NamedTemporaryFile(delete=False) as tf:
            wrpcap(tf.name, orig_packets)
            orig_packets_bytes = tf.name
        
        print(f"ğŸ“¦ æˆåŠŸè¯»å– {len(orig_packets)} ä¸ªæ•°æ®åŒ…")
        
        # ä¸»åŠ¨é‡Šæ”¾åŸå§‹PCAPæ•°æ®
        del orig_packets
        gc.collect()
        
        # 2. è®¡ç®—æ‰¹æ¬¡åˆ†å‰²
        BATCH_SIZE = pcap_write_interval
        total_batches = total_iterations // BATCH_SIZE
        remain = total_iterations % BATCH_SIZE
        
        print(f"ğŸ“Š æ‰¹æ¬¡ä¿¡æ¯: {total_batches} ä¸ªå®Œæ•´æ‰¹æ¬¡ + {remain} ä¸ªå‰©ä½™")
        
        def get_outfile(base, idx):
            """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
            base_name, ext = os.path.splitext(base)
            return f"{base_name}_{idx+1:03d}{ext}"
        
        # 3. ä¼˜åŒ–çš„æ··åˆå¤„ç†æ¶æ„ - å…±äº«è¿›ç¨‹æ± 
        batch_idx = 0
        
        # âœ… å…³é”®ä¼˜åŒ–ï¼šåˆ›å»ºä¸€ä¸ªé•¿ç”Ÿå‘½å‘¨æœŸçš„è¿›ç¨‹æ± ï¼Œé¿å…é‡å»ºå¼€é”€
        with ProcessPoolExecutor(max_workers=process_workers) as shared_executor:
            with ThreadPoolExecutor(max_workers=thread_workers) as file_writer:
                
                # é¢„åˆ›å»ºå¤„ç†å‡½æ•°ï¼Œé¿å…é‡å¤åˆ›å»º
                func = partial(process_one_group_n11, 
                             orig_packets_bytes=orig_packets_bytes,
                             ip_num=IP_NUM, sport_num=SPORT_NUM)
                
                # å¤„ç†å®Œæ•´æ‰¹æ¬¡
                for i in range(total_batches):
                    print(f"ğŸš€ å¤„ç†æ‰¹æ¬¡ {i+1}/{total_batches + (1 if remain > 0 else 0)}")
                    
                    # âœ… ä½¿ç”¨å…±äº«è¿›ç¨‹æ± ï¼Œé¿å…é‡å»º
                    batch_start_time = time.time()
                    results = shared_executor.map(func, range(i * BATCH_SIZE, (i + 1) * BATCH_SIZE))
                    
                    # æ”¶é›†å¤„ç†ç»“æœ
                    all_modified_packets = []
                    for group_bytes in tqdm(results, total=BATCH_SIZE, 
                                          desc=f"Batch {i+1}", ncols=80):
                        all_modified_packets.extend(group_bytes)
                    
                    batch_process_time = time.time() - batch_start_time
                    
                    # å¼‚æ­¥å†™å…¥æ–‡ä»¶
                    out_file = get_outfile(pcap_out, batch_idx)
                    file_writer.submit(async_write_pcap, out_file, all_modified_packets)
                    
                    # âœ… ä¼˜åŒ–å†…å­˜æ¸…ç†ï¼šå‡å°‘gc.collect()é¢‘ç‡
                    del all_modified_packets
                    if i % 3 == 0:  # æ¯3ä¸ªæ‰¹æ¬¡æ‰å¼ºåˆ¶å›æ”¶ä¸€æ¬¡
                        gc.collect()
                    
                    batch_idx += 1
                    print(f"ğŸ“Š æ‰¹æ¬¡ {i+1} å¤„ç†è€—æ—¶: {batch_process_time:.2f}ç§’")
                
                # å¤„ç†å‰©ä½™ç»„
                if remain > 0:
                    print(f"ğŸ”„ å¤„ç†å‰©ä½™æ‰¹æ¬¡ {batch_idx+1}/{total_batches + 1}")
                    
                    batch_start_time = time.time()
                    results = shared_executor.map(func, range(total_batches * BATCH_SIZE, total_iterations))
                    
                    all_modified_packets = []
                    for group_bytes in tqdm(results, total=remain, 
                                          desc=f"Batch {batch_idx+1}", ncols=80):
                        all_modified_packets.extend(group_bytes)
                    
                    batch_process_time = time.time() - batch_start_time
                    
                    out_file = get_outfile(pcap_out, batch_idx)
                    file_writer.submit(async_write_pcap, out_file, all_modified_packets)
                    
                    del all_modified_packets
                    print(f"ğŸ“Š å‰©ä½™æ‰¹æ¬¡å¤„ç†è€—æ—¶: {batch_process_time:.2f}ç§’")
                
                # ç­‰å¾…æ‰€æœ‰å†™ä»»åŠ¡å®Œæˆ
                print("â³ ç­‰å¾…æ‰€æœ‰æ–‡ä»¶å†™å…¥å®Œæˆ...")
                file_writer.shutdown(wait=True)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(orig_packets_bytes)
        gc.collect()
        
        # ç»Ÿè®¡ä¿¡æ¯
        end_time = time.time()
        duration = end_time - start_time
        speed = total_iterations / duration if duration > 0 else 0
        
        print(f"\nâœ… N11ä¼˜åŒ–ç‰ˆæ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å¤„ç†: {total_iterations} ç»„æ•°æ®åŒ…")
        print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f} ç§’")
        print(f"ğŸš„ å¤„ç†é€Ÿåº¦: {speed:.0f} ç»„/ç§’")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {pcap_out}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def main():
    import argparse
    parser = argparse.ArgumentParser(description='N11æ‰¹é‡å¾ªç¯PCAPå¤„ç†å·¥å…·')
    parser.add_argument('-i', '--input', dest='input_file', default="pcap/N11_create_50p.pcap",
                        help='è¾“å…¥PCAPæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', dest='output_file', default="pcap/N11_create_6k.pcap",
                        help='è¾“å‡ºPCAPæ–‡ä»¶å‰ç¼€è·¯å¾„')
    parser.add_argument('-n', '--num', dest='num', type=int, default=6000,
                        help='å¾ªç¯æ¬¡æ•°ï¼Œç”ŸæˆæŠ¥æ–‡ç»„æ•°')
    parser.add_argument('--ip-num', dest='ip_num', type=int, default=2000,
                        help='IPå¾ªç¯æ•°é‡ï¼Œé»˜è®¤2000ï¼ˆsip1/dip1/upfIP1/gnbIP1ç»Ÿä¸€ä½¿ç”¨ï¼‰')
    parser.add_argument('--sport-num', dest='sport_num', type=int, default=20000,
                        help='sportç«¯å£å¾ªç¯æ•°é‡ï¼Œé»˜è®¤20000')
    parser.add_argument('--tac-num', dest='tac_num', type=int, default=1000000,
                        help='TACå¾ªç¯æ•°é‡ï¼Œé»˜è®¤1000000')
    parser.add_argument('--pcap-interval', dest='pcap_interval', type=int, default=200000,                        help='æ¯å¤šå°‘æ¬¡å¾ªç¯å†™ä¸€ä¸ªPCAPæ–‡ä»¶ï¼Œé»˜è®¤200000')
    parser.add_argument('--threads', dest='threads', type=int, default=6,
                        help='çº¿ç¨‹æ•°ï¼Œé»˜è®¤6')
    parser.add_argument('--architecture', dest='architecture', 
                        choices=['original', 'n16', 'n16-optimized'], default='n16',
                        help='å¤„ç†æ¶æ„ï¼šoriginal(åŸå§‹ThreadPool) æˆ– n16(ProcessPool+ThreadPoolæ··åˆ) æˆ– n16-optimized(ä¼˜åŒ–ç‰ˆï¼Œè§£å†³ç¬¬äºŒæ‰¹æ¬¡é€Ÿåº¦é—®é¢˜)ï¼Œé»˜è®¤n16')
    parser.add_argument('--process-workers', dest='process_workers', type=int, default=6,
                        help='è¿›ç¨‹æ± å¤§å°ï¼Œé»˜è®¤6ï¼ˆä»…N16æ¶æ„ä½¿ç”¨ï¼‰')
    parser.add_argument('--thread-workers', dest='thread_workers', type=int, default=4,
                        help='çº¿ç¨‹æ± å¤§å°ï¼Œé»˜è®¤4ï¼ˆä»…N16æ¶æ„ä½¿ç”¨ï¼‰')
    
    args = parser.parse_args()
      # æ›´æ–°å…¨å±€é…ç½®
    global IP_NUM, SPORT_NUM, TAC_NUM
    IP_NUM = args.ip_num
    SPORT_NUM = args.sport_num
    TAC_NUM = args.tac_num
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_file):
        print(f"é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        return
      # æ ¹æ®é€‰æ‹©çš„æ¶æ„å¯åŠ¨å¤„ç†
    if args.architecture == 'n16-optimized':
        print("ğŸš€ ä½¿ç”¨N16ä¼˜åŒ–ç‰ˆæ··åˆæ¶æ„ (å…±äº«è¿›ç¨‹æ± ï¼Œè§£å†³ç¬¬äºŒæ‰¹æ¬¡é€Ÿåº¦é—®é¢˜)")
        main_batch_n16_style_optimized(
            pcap_in=args.input_file,
            pcap_out=args.output_file,
            total_iterations=args.num,
            pcap_write_interval=args.pcap_interval,
            process_workers=args.process_workers,
            thread_workers=args.thread_workers
        )
    elif args.architecture == 'n16':
        print("ğŸš€ ä½¿ç”¨N16é£æ ¼æ··åˆæ¶æ„ (ProcessPoolExecutor + ThreadPoolExecutor)")
        main_batch_n16_style(
            pcap_in=args.input_file,
            pcap_out=args.output_file,
            total_iterations=args.num,
            pcap_write_interval=args.pcap_interval,
            process_workers=args.process_workers,
            thread_workers=args.thread_workers
        )
    else:
        print("ğŸ”„ ä½¿ç”¨åŸå§‹ThreadPoolExecutoræ¶æ„")
        main_batch_loop(
            pcap_in=args.input_file,
            pcap_out=args.output_file,
            total_iterations=args.num,
            pcap_write_interval=args.pcap_interval,
            max_workers=args.threads
        )

if __name__ == "__main__":
    print("=== N11æ‰¹é‡å¾ªç¯å¤„ç†ç¨‹åºå¯åŠ¨ ===")
    print(f"ğŸ—ï¸ æ”¯æŒä¸‰ç§æ¶æ„:")
    print(f"   - original: åŸå§‹ThreadPoolExecutoræ¶æ„")  
    print(f"   - n16: N16é£æ ¼ProcessPoolExecutor+ThreadPoolExecutoræ··åˆæ¶æ„")
    print(f"   - n16-optimized: ä¼˜åŒ–ç‰ˆæ··åˆæ¶æ„ (æ¨èï¼Œè§£å†³ç¬¬äºŒæ‰¹æ¬¡é€Ÿåº¦é—®é¢˜)")
    print(f"ğŸ“‹ åˆå§‹é…ç½®:")
    print(f"  sip1èµ·å§‹å€¼: {INITIAL_SIP1}")
    print(f"  dip1èµ·å§‹å€¼: {INITIAL_DIP1}")
    print(f"  imsi1èµ·å§‹å€¼: {INITIAL_IMSI1}")
    print(f"  imei14èµ·å§‹å€¼: {INITIAL_IMEI14}")
    print(f"  gpsi1èµ·å§‹å€¼: {INITIAL_GPSI1}")
    print(f"  PduAddr1èµ·å§‹å€¼: {INITIAL_PDUADDR1}")
    print(f"  dnn1èµ·å§‹å€¼: {INITIAL_DNN1}")
    print(f"  tac1èµ·å§‹å€¼: {INITIAL_TAC1}")
    print(f"  cgi1èµ·å§‹å€¼: {INITIAL_CGI1}")
    print(f"  upfIP1èµ·å§‹å€¼: {INITIAL_UPFIP1}")
    print(f"  upTEID1èµ·å§‹å€¼: {hex(INITIAL_UPTEID1)}")
    print(f"  gnbIP1èµ·å§‹å€¼: {INITIAL_GNBIP1}")
    print(f"  dnTEID1èµ·å§‹å€¼: {hex(INITIAL_DNTEID1)}")
    print(f"  sportç«¯å£èµ·å§‹å€¼: {INITIAL_SPORT1}(+3é€’å¢), {INITIAL_SPORT2}, {INITIAL_SPORT3}")
    print(f"  é»˜è®¤è¾“å…¥æ–‡ä»¶: pcap/N11_create_50p.pcap")
    print(f"  é»˜è®¤è¾“å‡ºæ–‡ä»¶: pcap/N11_create_batch.pcap")
    print(f"  ç»Ÿä¸€IPå¾ªç¯æ•°é‡: {IP_NUM}")
    print(f"  TACå¾ªç¯æ•°é‡: {TAC_NUM}")
    
    try:
        main()
        print("âœ… ç¨‹åºæ­£å¸¸ç»“æŸ")
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸ç»“æŸ: {e}")
        import traceback
        traceback.print_exc()